\begin{tabular}{lrrrr}
\toprule
response\_type & normal & order\_independent & only\_parallel\_attention & only\_parallel\_attention\_reversed \\
model &  &  &  &  \\
\midrule
WizardLM/WizardLM-7B-V1.0 & 0.325 & 0.325 & 0.325 & 0.325 \\
gpt2 & 0.199 & 0.206 & 0.217 & 0.213 \\
lmsys/vicuna-7b-v1.5 & 1.000 & 0.500 & 0.500 & 0.500 \\
meta-llama/Llama-2-13b-chat-hf & 0.857 & 0.714 & 0.857 & 0.571 \\
meta-llama/Llama-2-13b-hf & 0.372 & 0.302 & 0.256 & 0.233 \\
meta-llama/Llama-2-7b-chat-hf & 0.364 & 0.409 & 0.409 & 0.318 \\
meta-llama/Llama-2-7b-hf & 0.222 & 0.240 & 0.269 & 0.234 \\
\bottomrule
\end{tabular}
