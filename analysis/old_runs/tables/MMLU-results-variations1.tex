\begin{tabular}{lrrrr}
\toprule
response\_type & normal & order\_independent & only\_parallel\_attention & only\_parallel\_attention\_reversed \\
model &  &  &  &  \\
\midrule
WizardLM/WizardLM-7B-V1.0 & 0.405 & 0.405 & 0.405 & 0.405 \\
gpt2 & 0.253 & 0.255 & 0.258 & 0.258 \\
lmsys/vicuna-7b-v1.5 & 0.264 & 0.275 & 0.266 & 0.263 \\
meta-llama/Llama-2-13b-chat-hf & 0.281 & 0.291 & 0.291 & 0.301 \\
meta-llama/Llama-2-13b-hf & 0.252 & 0.254 & 0.240 & 0.247 \\
meta-llama/Llama-2-7b-chat-hf & 0.290 & 0.279 & 0.273 & 0.276 \\
meta-llama/Llama-2-7b-hf & 0.261 & 0.262 & 0.254 & 0.267 \\
\bottomrule
\end{tabular}
