{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cfc4ed-afbf-4aaa-b840-7a9718695b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import order_independent_llm\n",
    "import order_independent_llm.plot_helpers\n",
    "import json\n",
    "import seaborn as sns\n",
    "from functools import lru_cache\n",
    "import multiprocessing\n",
    "\n",
    "# Base paths\n",
    "BASE_DIR = \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp\"\n",
    "RESULTS_DIR_MMLU = \"results/mmlu_quoted\"\n",
    "RESULTS_DIR_CSQA = \"results/csqa_quoted\"\n",
    "OUTPUT_DIR = \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/20250105-005619_tags-False\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad150afd-3ab9-4dd2-9500-831105688600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model pairs (pre and post finetuning)\n",
    "model_pairs = [\n",
    "    {\n",
    "        \"name\": \"Llama-2-7b\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-7b-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/20250105-005619_tags-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Llama-2-7b : QA\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-7b-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa/20250106-022456-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "15fe8c0f-2231-493b-8595-d89d7fa9cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model pairs (pre and post finetuning)\n",
    "# NOTE: all trained with 2 epochs (I want to switch back to 3)\n",
    "model_pairs = [\n",
    "    {\n",
    "        \"name\": \"Llama-2-7b : QA\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-7b-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa/20250109-090124-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Llama-2-7b : QA+wiki\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-7b-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa_wiki/20250109-092335-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Llama-2-7b : Q only\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-7b-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/20250105-005619_tags-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "    #{\n",
    "    #    \"name\": \"Llama-2-7b : QA (Prev)\",\n",
    "    #    \"pre_path\": \"meta-llama_Llama-2-7b-hf-50\",\n",
    "    #    \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa/20250106-022456-False\", # stores benchmarks.jsonl\n",
    "    #},\n",
    "    {\n",
    "        \"name\": \"Llama-2-7b : QA+s2d\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-7b-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa_s2d/20250109-094716-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fe5e8b29-b81c-4988-a5e2-6080cf91a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 models for comparison\n",
    "model_pairs = [\n",
    "    {\n",
    "        \"name\": \"Llama-2-7b : QA+wiki\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-7b-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa_wiki/20250109-092335-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Llama-2-7b-chat : QA+wiki\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-7b-chat-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-chat-hf/mmlu_quoted_qa_wiki/20250110-001813-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Llama-2-13b : QA+wiki\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-13b-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-13b-hf/mmlu_quoted_qa_wiki/20250110-002528-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Llama-2-13b-chat : QA+wiki\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-13b-chat-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-13b-chat-hf/mmlu_quoted_qa_wiki/20250109-235941-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6dc68407-fb42-4468-a39f-1e448a77693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama-2-7b, trained on either MMLU or CSQA\n",
    "model_pairs = [\n",
    "    {\n",
    "        \"name\": \"Llama-2-7b : QA+wiki\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-7b-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa_wiki/20250109-092335-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Llama-2-7b : QA+wiki : train_csqa\",\n",
    "        \"pre_path\": \"meta-llama_Llama-2-7b-hf-50\",\n",
    "        \"output_dir\": \"/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/csqa_quoted_qa_wiki/20250112-040235-False\", # stores benchmarks.jsonl\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3844e5fb-016c-4c7f-a88b-c3bd84377ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa/20250109-090124-False\n",
      "/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa_wiki/20250109-092335-False\n",
      "/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/20250105-005619_tags-False\n",
      "/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa_s2d/20250109-094716-False\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model_pairs)):\n",
    "    print(model_pairs[i][\"output_dir\"])\n",
    "    if \"s2d\" not in model_pairs[i][\"output_dir\"]:\n",
    "        model_pairs[i][\"post_path_csqa\"] = f\"results/csqa_quoted/\"+model_pairs[i][\"output_dir\"].replace(\"/\",\"_\")+\"_final_weights-50\"\n",
    "        model_pairs[i][\"post_path_mmlu\"] = f\"results/mmlu_quoted/\"+model_pairs[i][\"output_dir\"].replace(\"/\",\"_\")+\"_final_weights-50\"\n",
    "    else:\n",
    "        model_pairs[i][\"post_path_csqa\"] = f\"results/csqa_quoted_s2d/\"+model_pairs[i][\"output_dir\"].replace(\"/\",\"_\")+\"_final_weights-50\"\n",
    "        model_pairs[i][\"post_path_mmlu\"] = f\"results/mmlu_quoted_s2d/\"+model_pairs[i][\"output_dir\"].replace(\"/\",\"_\")+\"_final_weights-50\"\n",
    "    model_pairs[i][\"pre_path_csqa\"] = f\"results/csqa_quoted/\"+model_pairs[i][\"pre_path\"]\n",
    "    model_pairs[i][\"pre_path_mmlu\"] = f\"results/mmlu_quoted/\"+model_pairs[i][\"pre_path\"]\n",
    "    model_pairs[i][\"pre_path_csqa_perm\"] = f\"results/csqa_quoted_permutations/\"+model_pairs[i][\"pre_path\"]\n",
    "    model_pairs[i][\"pre_path_mmlu_perm\"] = f\"results/mmlu_quoted_permutations/\"+model_pairs[i][\"pre_path\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3a0db5c7-6d83-4263-b1c3-8845a5d95e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Llama-2-7b after 1 epoch of training (as comparison to see if catastrophic forgetting is reduced)\n",
    "model_pairs.append({k:v for k,v in model_pairs[0].items()})\n",
    "model_pairs[-1][\"name\"] = \"Llama-2-7b : QA+wiki (1 epoch)\"\n",
    "model_pairs[-1][\"post_path_csqa\"] = model_pairs[-1][\"post_path_csqa\"].replace(\"final_weights\",\"checkpoint-493\")\n",
    "model_pairs[-1][\"post_path_mmlu\"] = model_pairs[-1][\"post_path_mmlu\"].replace(\"final_weights\",\"checkpoint-493\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8d8709bb-17aa-46ca-bdf1-8a415e7c3e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Llama-2-7b : QA+wiki',\n",
       "  'pre_path': 'meta-llama_Llama-2-7b-hf-50',\n",
       "  'output_dir': '/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa_wiki/20250109-092335-False',\n",
       "  'post_path_csqa': 'results/csqa_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-hf_mmlu_quoted_qa_wiki_20250109-092335-False_final_weights-50',\n",
       "  'post_path_mmlu': 'results/mmlu_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-hf_mmlu_quoted_qa_wiki_20250109-092335-False_final_weights-50',\n",
       "  'pre_path_csqa': 'results/csqa_quoted/meta-llama_Llama-2-7b-hf-50',\n",
       "  'pre_path_mmlu': 'results/mmlu_quoted/meta-llama_Llama-2-7b-hf-50',\n",
       "  'pre_path_csqa_perm': 'results/csqa_quoted_permutations/meta-llama_Llama-2-7b-hf-50',\n",
       "  'pre_path_mmlu_perm': 'results/mmlu_quoted_permutations/meta-llama_Llama-2-7b-hf-50'},\n",
       " {'name': 'Llama-2-7b : QA+wiki : train_csqa',\n",
       "  'pre_path': 'meta-llama_Llama-2-7b-hf-50',\n",
       "  'output_dir': '/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/csqa_quoted_qa_wiki/20250112-040235-False',\n",
       "  'post_path_csqa': 'results/csqa_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-hf_csqa_quoted_qa_wiki_20250112-040235-False_final_weights-50',\n",
       "  'post_path_mmlu': 'results/mmlu_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-hf_csqa_quoted_qa_wiki_20250112-040235-False_final_weights-50',\n",
       "  'pre_path_csqa': 'results/csqa_quoted/meta-llama_Llama-2-7b-hf-50',\n",
       "  'pre_path_mmlu': 'results/mmlu_quoted/meta-llama_Llama-2-7b-hf-50',\n",
       "  'pre_path_csqa_perm': 'results/csqa_quoted_permutations/meta-llama_Llama-2-7b-hf-50',\n",
       "  'pre_path_mmlu_perm': 'results/mmlu_quoted_permutations/meta-llama_Llama-2-7b-hf-50'},\n",
       " {'name': 'Llama-2-7b : QA+wiki (1 epoch)',\n",
       "  'pre_path': 'meta-llama_Llama-2-7b-hf-50',\n",
       "  'output_dir': '/n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa_wiki/20250109-092335-False',\n",
       "  'post_path_csqa': 'results/csqa_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-hf_mmlu_quoted_qa_wiki_20250109-092335-False_checkpoint-493-50',\n",
       "  'post_path_mmlu': 'results/mmlu_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-hf_mmlu_quoted_qa_wiki_20250109-092335-False_checkpoint-493-50',\n",
       "  'pre_path_csqa': 'results/csqa_quoted/meta-llama_Llama-2-7b-hf-50',\n",
       "  'pre_path_mmlu': 'results/mmlu_quoted/meta-llama_Llama-2-7b-hf-50',\n",
       "  'pre_path_csqa_perm': 'results/csqa_quoted_permutations/meta-llama_Llama-2-7b-hf-50',\n",
       "  'pre_path_mmlu_perm': 'results/mmlu_quoted_permutations/meta-llama_Llama-2-7b-hf-50'}]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a109d440-1109-44d1-8cf4-92e1c2a8e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/csqa_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-hf_mmlu_quoted_qa_wiki_20250109-092335-False_checkpoint-493-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ea95b-5122-4565-8259-1f974c57913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "@lru_cache\n",
    "def load_results(model_path):\n",
    "    \"\"\"Load results for a given model and dataset type (MMLU or CSQA)\"\"\"\n",
    "    files = glob.glob(f\"*{model_path}/*.jsonl\")\n",
    "    \n",
    "    if not files:\n",
    "        model_path = model_path.replace(\"final_weights-50\",\"final_weights_-50\")\n",
    "        files = glob.glob(f\"*{model_path}/*.jsonl\")\n",
    "    if not files:\n",
    "        model_path = \"/n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/\"+model_path\n",
    "        files = glob.glob(f\"{model_path}/*.jsonl\")\n",
    "    if not files:\n",
    "        model_path = model_path.replace(\"final_weights_-50\",\"final_weights-50\")\n",
    "        files = glob.glob(f\"{model_path}/*.jsonl\")\n",
    "    if not files:\n",
    "        print(f\"No results found for {model_path}\")\n",
    "        return None\n",
    "    \n",
    "    #df = pd.concat([order_independent_llm.load_to_dataframe(f, fail_on_empty=False) for f in files])\n",
    "    def load(x):\n",
    "        return order_independent_llm.load_to_dataframe(x,fail_on_empty=False, include_probs=False)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        dataframes = list(executor.map(load, files))\n",
    "    \n",
    "    # Combine all dataframes into one\n",
    "    df = pd.concat(dataframes)\n",
    "    print(f\"Loading {df.shape} results from {model_path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2daffeae-1368-4de3-9740-c4a01a3dc374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_permutation_boxplot(model_results, dataset_type, output_name, suffix=\"\"):\n",
    "    \"\"\"Create boxplot showing distribution of accuracies across permutations for all models\"\"\"\n",
    "    df = pd.concat([model_info['pre_data_perm'].assign(model=model_info['name']) for model_info in model_results])#.drop_duplicates()\n",
    "    df_post = pd.concat([model_info['post_data'].assign(model=model_info['name']) for model_info in model_results])#.drop_duplicates()\n",
    "    '''\n",
    "    'response_type', 'model', 'max_new_tokens', 'order_independent_output',\n",
    "       'pad_attention', 'text_output', 'is_correct_answer',\n",
    "       'correct_answer_prob', 'raw_output_contains_correct_answer_only',\n",
    "       'edit_position', 'edit_attention', 'label_scores', 'label_perplexities',\n",
    "       'probs', 'meta_label', 'meta_incorrect_answers', 'prompt', 'file_name'\n",
    "    '''\n",
    "    #df_post['model'] = \"meta-llama/\" + df_post['model']\n",
    "    #df['model'] = \"meta-llama/\" + df['model']\n",
    "\n",
    "    # only include rows with matching file_name and prompt\n",
    "    common_keys = set(df['prompt']) & set(df_post['prompt'])\n",
    "    df = df[df['prompt'].isin(common_keys)]\n",
    "    df_post = df_post[df_post['prompt'].isin(common_keys) & (df_post['response_type'] == 'order_independent')]\n",
    "    print(f\"After filtering to only create permutation boxplot from common rows: df_post.shape={df_post.shape}\")\n",
    "    print(df_post[\"model\"].value_counts())\n",
    "    #print(df['model'].value_counts())\n",
    "    perms = list(df['response_type'].unique())[3:]\n",
    "    \n",
    "    # 1. Gather all y-values in one array/Series:\n",
    "    df_means       = df[df['response_type'].isin(perms)]\\\n",
    "                        [['model','is_correct_answer','response_type']]\\\n",
    "                        .groupby(['model','response_type'])\\\n",
    "                        .mean()['is_correct_answer']\n",
    "    df_post_means  = df_post[df_post['response_type'] == 'order_independent']\\\n",
    "                        [['model','is_correct_answer','response_type']]\\\n",
    "                        .groupby(['model','response_type'])\\\n",
    "                        .mean()['is_correct_answer']\n",
    "    df_pre_means   = df[df['response_type'] == 'order_independent']\\\n",
    "                        [['model','is_correct_answer','response_type']]\\\n",
    "                        .groupby(['model','response_type'])\\\n",
    "                        .mean()['is_correct_answer']\n",
    "    \n",
    "    all_y_values = pd.concat([df_means, df_post_means, df_pre_means])\n",
    "    \n",
    "    # 2. Compute the global min and max of all_y_values:\n",
    "    y_min, y_max = all_y_values.min(), all_y_values.max()\n",
    "    \n",
    "    # 3. Plot:\n",
    "    fig, ax = plt.subplots(figsize = (7,5))\n",
    "    \n",
    "    sns.boxplot(\n",
    "        x='model',\n",
    "        y='is_correct_answer',\n",
    "        data=df_means.reset_index(),\n",
    "        ax=ax,\n",
    "        whis=[0, 100],\n",
    "        width=.6,\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        x='model',\n",
    "        y='is_correct_answer',\n",
    "        data=df_means.reset_index(),\n",
    "        ax=ax,\n",
    "        label='Normal Model',\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x='model',\n",
    "        y='is_correct_answer',\n",
    "        data=df_post_means.reset_index(),\n",
    "        ax=ax,\n",
    "        s=100,\n",
    "        label='Post-Finetuning Order Independent Model',\n",
    "        zorder=5,\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x='model',\n",
    "        y='is_correct_answer',\n",
    "        data=df_pre_means.reset_index(),\n",
    "        ax=ax,\n",
    "        s=100,\n",
    "        label='Pre-Finetuning Order Independent Model',\n",
    "        zorder=4,\n",
    "    )\n",
    "    \n",
    "    # Now ensure the y-limit covers the entire data range:\n",
    "    ax.set_ylim([y_min-0.03, y_max+0.03])\n",
    "    ax.set_xticklabels([l._text.split('/')[-1] for l in ax.get_xticklabels()], rotation=90, ha='right')\n",
    "    \n",
    "    ax.legend(ax.get_legend_handles_labels()[0][-2:],ax.get_legend_handles_labels()[1][-2:],bbox_to_anchor=(1,1),loc = 'upper left')\n",
    "    ax.set_xlabel(\"Model\")\n",
    "    ax.set_ylabel(f\"{dataset_type} Top 1 Accuracy\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{suffix}/{output_name}_boxplot.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Create DataFrame with Pre-OID and Post-OID columns\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Pre-OID': df_pre_means.reset_index()['is_correct_answer'],\n",
    "        'Post-OID': df_post_means.reset_index()['is_correct_answer'],\n",
    "    })\n",
    "    \n",
    "    # Ensure model is the index\n",
    "    # TODO: double-check that boxplot indexing labels is correct!!!\n",
    "    comparison_df.index.name = 'model'\n",
    "    comparison_df.index = df_post_means.reset_index()['model'].unique().tolist()\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    print(f\"Boxplot {dataset_type} Accuracy:\")\n",
    "    print(comparison_df.round(3))  # Round to 3 decimal places for cleaner output\n",
    "\n",
    "def create_comparison_barplot(model_results, dataset_type, output_name, suffix=\"\"):\n",
    "    \"\"\"Create barplot comparing normal vs order independent accuracies for all models\"\"\"\n",
    "    #print(\"=======Barplot=========\")\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    plot_data = []\n",
    "    \n",
    "    # Process each model's data\n",
    "    for model_info in model_results:\n",
    "        pre_data = model_info['pre_data']\n",
    "        post_data = model_info['post_data']\n",
    "        #print(\"Pre-filter:\",pre_data.shape,post_data.shape)\n",
    "        common_keys = set(pre_data['prompt']) & set(post_data['prompt'])\n",
    "        pre_data = pre_data[pre_data['prompt'].isin(common_keys)]\n",
    "        post_data = post_data[post_data['prompt'].isin(common_keys) & (post_data['response_type'] == 'order_independent')]\n",
    "        #print(\"Post-filter:\",pre_data.shape,post_data.shape)\n",
    "        print(model_info['name'],post_data.shape[0],\"post datapoints\")\n",
    "        if post_data.shape[0]==0:\n",
    "            continue\n",
    "        model_name = model_info['name']\n",
    "        \n",
    "        if pre_data is None:\n",
    "            continue\n",
    "            \n",
    "        # Pre-finetuning normal accuracy with error bars\n",
    "        df_pivot = pre_data.drop_duplicates(['prompt', 'response_type']).pivot(\n",
    "            index='prompt',\n",
    "            columns='response_type',\n",
    "            values='is_correct_answer'\n",
    "        )[['normal', 'normal_reversed']]\n",
    "        # Error is proportion where normal=False but reversed=True\n",
    "        error = ((~df_pivot['normal']) & (df_pivot['normal_reversed'])).mean()#float(df_mean.loc[(False, True)] if (False, True) in df_mean.index else 0)\n",
    "        \n",
    "        # Normal accuracy is mean of normal responses\n",
    "        normal_acc = pre_data[pre_data['response_type'] == 'normal']['is_correct_answer'].mean()\n",
    "        \n",
    "        plot_data.append({\n",
    "            'Model': model_name,\n",
    "            'Type': 'Normal',\n",
    "            'Accuracy': normal_acc,\n",
    "            'Error': error\n",
    "        })\n",
    "        \n",
    "        # Pre-finetuning order independent\n",
    "        pre_oid = pre_data[pre_data['response_type'] == 'order_independent']['is_correct_answer'].mean()\n",
    "        plot_data.append({\n",
    "            'Model': model_name,\n",
    "            'Type': 'Pre-OID',\n",
    "            'Accuracy': pre_oid,\n",
    "            'Error': 0\n",
    "        })\n",
    "        \n",
    "        # Post-finetuning order independent\n",
    "        if post_data is not None:\n",
    "            post_oid = post_data[post_data['response_type'] == 'order_independent']['is_correct_answer'].mean()\n",
    "            plot_data.append({\n",
    "                'Model': model_name,\n",
    "                'Type': 'Post-OID',\n",
    "                'Accuracy': post_oid,\n",
    "                'Error': 0,\n",
    "            })\n",
    "    \n",
    "    # Create plot\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "    # Create pivot table with Models as rows and Types as columns\n",
    "    reshaped_df = plot_df.pivot(index='Model', columns='Type', values='Accuracy')\n",
    "    \n",
    "    # Print the reshaped DataFrame\n",
    "    print(f\"Barplot {dataset_type} Accuracy:\")\n",
    "    print(reshaped_df[[\"Normal\",\"Pre-OID\",\"Post-OID\"]].round(3))  # Round to 3 decimal places for cleaner output\n",
    "    \n",
    "    # Create grouped barplot\n",
    "    sns.barplot(\n",
    "        data=plot_df,\n",
    "        x='Model',\n",
    "        y='Accuracy',\n",
    "        hue='Type',\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    # Add error bars\n",
    "    for i, model in enumerate(plot_df['Model'].unique()):\n",
    "        model_data = plot_df[plot_df['Model'] == model]\n",
    "        normal_data = model_data[model_data['Type'] == 'Normal']\n",
    "        if not normal_data.empty:\n",
    "            ax.errorbar(\n",
    "                x=i - 0.2,  # Adjust position to align with correct bar\n",
    "                y=normal_data['Accuracy'].iloc[0],\n",
    "                yerr=normal_data['Error'].iloc[0],\n",
    "                fmt='none',\n",
    "                c='black'\n",
    "            )\n",
    "    \n",
    "    ax.set_title(f\"{dataset_type} Accuracy Comparison - All Models\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Top 1 Accuracy\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(title=\"\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{suffix}/{output_name}_barplot.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4a0d7c5d-9c8b-43f3-9c04-06fa670a73dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_perplexity_results(model_dir):\n",
    "    \"\"\"Load WikiText-103 perplexity results from benchmarks.jsonl\"\"\"\n",
    "    benchmarks_file = os.path.join(model_dir, \"benchmarks.jsonl\")\n",
    "    if not os.path.exists(benchmarks_file):\n",
    "        print(f\"No benchmarks file found at {benchmarks_file}\")\n",
    "        return None\n",
    "        \n",
    "    results = []\n",
    "    with open(benchmarks_file, 'r') as f:\n",
    "        for line in f:\n",
    "            results.append(json.loads(line))\n",
    "            \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Extract initial and final weights perplexity\n",
    "    initial_perp = df[df['model_path'].str.contains('initial_weights')]['wikitext_perplexity'].iloc[0]\n",
    "    final_perp = df[df['model_path'].str.contains('final_weights')]['wikitext_perplexity'].iloc[0]\n",
    "    \n",
    "    return {\n",
    "        'initial_perplexity': initial_perp,\n",
    "        'final_perplexity': final_perp\n",
    "    }\n",
    "\n",
    "def load_loss_data(model_dir):\n",
    "    \"\"\"Load and process training loss data\"\"\"\n",
    "    loss_file = os.path.join(model_dir, \"loss.jsonl\")\n",
    "    if not os.path.exists(loss_file):\n",
    "        print(f\"No loss file found at {loss_file}\")\n",
    "        return None\n",
    "    \n",
    "    # Read loss data\n",
    "    losses = []\n",
    "    with open(loss_file, 'r') as f:\n",
    "        for line in f:\n",
    "            losses.append(json.loads(line))\n",
    "    \n",
    "    # Convert to DataFrame and deduplicate\n",
    "    df = pd.DataFrame(losses).drop_duplicates()\n",
    "    \n",
    "    # Filter and process data\n",
    "    df = df[df['phase'] != 'final']  # Remove final phase\n",
    "    #df.loc[df['phase'] == 'initial', 'epoch'] = -1  # Set initial phase to epoch -1\n",
    "    df.loc[df['phase'] == 'initial', 'epoch'] = 0  # Set initial phase to epoch 0\n",
    "    df.loc[df['phase'] == 'epoch', 'epoch'] = df.loc[df['phase'] == 'epoch', 'epoch'] + 1  # Shift epochs up by 1\n",
    "    df = df.sort_values('epoch')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_perplexity_plot(perplexity_data, suffix=\"\"):\n",
    "    \"\"\"Create barplot comparing initial and final perplexities across models\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    plot_data = []\n",
    "    for model_name, perp in perplexity_data.items():\n",
    "        if perp is not None:\n",
    "            plot_data.extend([\n",
    "                {\n",
    "                    'Model': model_name,\n",
    "                    'Type': 'Initial Weights',\n",
    "                    'Perplexity': perp['initial_perplexity']\n",
    "                },\n",
    "                {\n",
    "                    'Model': model_name,\n",
    "                    'Type': 'Final Weights',\n",
    "                    'Perplexity': perp['final_perplexity']\n",
    "                }\n",
    "            ])\n",
    "    \n",
    "    if not plot_data:\n",
    "        print(\"No perplexity data available\")\n",
    "        return\n",
    "        \n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # Create grouped barplot\n",
    "    sns.barplot(\n",
    "        data=plot_df,\n",
    "        x='Model',\n",
    "        y='Perplexity',\n",
    "        hue='Type',\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title(\"WikiText-103 Perplexity - Finetuning\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Perplexity\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(title=\"\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{suffix}/finetuning_perplexity.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_loss_plot(model_losses, suffix=\"\"):\n",
    "    \"\"\"Create lineplot of training and validation losses\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    for model_name, loss_df in model_losses.items():\n",
    "        if loss_df is not None:\n",
    "            # Plot train loss\n",
    "            ax.plot(loss_df['epoch'], loss_df['train_loss'], \n",
    "                   label=f'{model_name} (train)', \n",
    "                   marker='o')\n",
    "            \n",
    "            # Plot eval loss\n",
    "            ax.plot(loss_df['epoch'], loss_df['eval_loss'], \n",
    "                   label=f'{model_name} (val)', \n",
    "                   marker='o', \n",
    "                   linestyle='--')\n",
    "    \n",
    "    ax.set_title(\"Training and Validation Loss\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/{suffix}/finetuning_loss.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def analyze_perplexity(model_pairs, suffix=\"\"):\n",
    "    \"\"\"Analyze perplexity and training loss for all models\"\"\"\n",
    "    # Create plots directory if it doesn't exist\n",
    "    os.makedirs(f\"plots/{suffix}\", exist_ok=True)\n",
    "    \n",
    "    # Collect perplexity data\n",
    "    perplexity_data = {}\n",
    "    model_losses = {}\n",
    "    \n",
    "    for pair in model_pairs:\n",
    "        # Load perplexity data\n",
    "        perp_results = load_perplexity_results(pair[\"output_dir\"])\n",
    "        if perp_results is not None:\n",
    "            perplexity_data[pair[\"name\"]] = perp_results\n",
    "            \n",
    "        # Load loss data\n",
    "        loss_results = load_loss_data(pair[\"output_dir\"])\n",
    "        if loss_results is not None:\n",
    "            model_losses[pair[\"name\"]] = loss_results\n",
    "    \n",
    "    # Create plots\n",
    "    create_perplexity_plot(perplexity_data, suffix)\n",
    "    create_loss_plot(model_losses, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a1daadb3-a278-4744-9303-8a5d906de7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(dataset_type, suffix=\"\"):\n",
    "    \"\"\"Analyze results for either MMLU or CSQA\"\"\"\n",
    "    os.makedirs(f\"plots/{suffix}\", exist_ok=True)\n",
    "    model_results = []\n",
    "    \n",
    "    # Collect all model results first\n",
    "    for pair in model_pairs:\n",
    "        # Load pre-finetuning results\n",
    "        pre_results = load_results(pair[f\"pre_path_{dataset_type.lower()}\"])\n",
    "        if pre_results is None:\n",
    "            continue\n",
    "            \n",
    "        # Load post-finetuning results\n",
    "        post_results = load_results(pair[f\"post_path_{dataset_type.lower()}\"])\n",
    "\n",
    "        pre_results_perm = load_results(pair[f\"pre_path_{dataset_type.lower()}_perm\"])\n",
    "        \n",
    "        model_results.append({\n",
    "            'name': pair['name'],\n",
    "            'pre_data': pre_results,\n",
    "            'post_data': post_results,\n",
    "            'pre_data_perm': pre_results_perm,\n",
    "        })\n",
    "\n",
    "    create_comparison_barplot(\n",
    "        model_results,\n",
    "        dataset_type,\n",
    "        f\"{dataset_type.lower()}\",\n",
    "        suffix,\n",
    "    )\n",
    "    \n",
    "    # Create plots with all models\n",
    "    create_permutation_boxplot(\n",
    "        model_results,\n",
    "        dataset_type,\n",
    "        f\"{dataset_type.lower()}\",\n",
    "        suffix,\n",
    "    )\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3b3f6ebe-4cf9-461b-810c-30a6bc15ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "\n",
    "def create_image_grid(image_dir, output_path, images_per_row=None):\n",
    "    \"\"\"\n",
    "    Create a grid of images from all PNGs in a directory\n",
    "    \n",
    "    Args:\n",
    "        image_dir: Directory containing PNG images\n",
    "        output_path: Path to save the output grid image\n",
    "        images_per_row: Number of images per row (optional, will calculate square grid if None)\n",
    "    \"\"\"\n",
    "    # Get all PNG files\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith('.png') and \"combined\" not in f]\n",
    "    if not image_files:\n",
    "        print(\"No PNG files found in directory\")\n",
    "        return\n",
    "        \n",
    "    # Open all images\n",
    "    images = [Image.open(os.path.join(image_dir, f)) for f in image_files]\n",
    "    \n",
    "    # Calculate grid size\n",
    "    n_images = len(images)\n",
    "    if images_per_row is None:\n",
    "        # Make a square grid\n",
    "        grid_size = math.ceil(math.sqrt(n_images))\n",
    "        n_rows = grid_size\n",
    "        n_cols = grid_size\n",
    "    else:\n",
    "        n_cols = images_per_row\n",
    "        n_rows = math.ceil(n_images / n_cols)\n",
    "    \n",
    "    # Get max dimensions\n",
    "    max_width = max(img.size[0] for img in images)\n",
    "    max_height = max(img.size[1] for img in images)\n",
    "    \n",
    "    # Create output image\n",
    "    grid_img = Image.new('RGB', \n",
    "                        (max_width * n_cols, max_height * n_rows),\n",
    "                        color='white')\n",
    "    \n",
    "    # Paste images into grid\n",
    "    for idx, img in enumerate(images):\n",
    "        row = idx // n_cols\n",
    "        col = idx % n_cols\n",
    "        grid_img.paste(img, (col * max_width, row * max_height))\n",
    "    \n",
    "    # Save result\n",
    "    grid_img.save(output_path)\n",
    "    print(f\"Grid image saved to {output_path}\")\n",
    "\n",
    "def create_megaimage(image_dir, images_per_row=None):\n",
    "    output_path = f\"{image_dir}/combined.png\"\n",
    "    # Create a square grid\n",
    "    create_image_grid(image_dir, output_path, images_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "10ab085f-7b99-4e67-abb5-75cd83076683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid image saved to plots/llama_family/combined.png\n",
      "Grid image saved to plots/train_method/combined.png\n"
     ]
    }
   ],
   "source": [
    "#create_megaimage(\"plots/ablations\")\n",
    "create_megaimage(\"plots/llama_family\", images_per_row=2)\n",
    "create_megaimage(\"plots/train_method\", images_per_row=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3078b80d-2749-430e-a002-0a061d53573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No loss file found at /n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa/20250109-090124-False/loss.jsonl\n",
      "No loss file found at /n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa_wiki/20250109-092335-False/loss.jsonl\n",
      "No loss file found at /n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/20250105-005619_tags-False/loss.jsonl\n",
      "No loss file found at /n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa_s2d/20250109-094716-False/loss.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "analyze_perplexity(model_pairs,\"ablations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fb6d06e6-3222-43b3-b4b5-aab78034da13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading (23655, 18) results from results/mmlu_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-hf_mmlu_quoted_qa_20250109-090124-False_final_weights-50\n",
      "Loading (20772, 18) results from results/mmlu_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-hf_20250105-005619_tags-False_final_weights-50\n",
      "Loading (25440, 18) results from results/mmlu_quoted_s2d/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-hf_mmlu_quoted_qa_s2d_20250109-094716-False_final_weights_-50\n",
      "Llama-2-7b : QA 6285 post datapoints\n",
      "Llama-2-7b : QA+wiki 6285 post datapoints\n",
      "Llama-2-7b : Q only 6038 post datapoints\n",
      "Llama-2-7b : QA+s2d 0 post datapoints\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['normal', 'normal_reversed'], dtype='object', name='response_type')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43manalyze_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMMLU\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mablations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[132], line 25\u001b[0m, in \u001b[0;36manalyze_dataset\u001b[0;34m(dataset_type, suffix)\u001b[0m\n\u001b[1;32m     16\u001b[0m     pre_results_perm \u001b[38;5;241m=\u001b[39m load_results(pair[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_path_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_type\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_perm\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     18\u001b[0m     model_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: pair[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_data\u001b[39m\u001b[38;5;124m'\u001b[39m: pre_results,\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_data\u001b[39m\u001b[38;5;124m'\u001b[39m: post_results,\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_data_perm\u001b[39m\u001b[38;5;124m'\u001b[39m: pre_results_perm,\n\u001b[1;32m     23\u001b[0m     })\n\u001b[0;32m---> 25\u001b[0m \u001b[43mcreate_comparison_barplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Create plots with all models\u001b[39;00m\n\u001b[1;32m     33\u001b[0m create_permutation_boxplot(\n\u001b[1;32m     34\u001b[0m     model_results,\n\u001b[1;32m     35\u001b[0m     dataset_type,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_type\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m     suffix,\n\u001b[1;32m     38\u001b[0m )\n",
      "Cell \u001b[0;32mIn[130], line 129\u001b[0m, in \u001b[0;36mcreate_comparison_barplot\u001b[0;34m(model_results, dataset_type, output_name, suffix)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Pre-finetuning normal accuracy with error bars\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m df_pivot \u001b[38;5;241m=\u001b[39m \u001b[43mpre_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_duplicates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresponse_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresponse_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mis_correct_answer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnormal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnormal_reversed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Error is proportion where normal=False but reversed=True\u001b[39;00m\n\u001b[1;32m    135\u001b[0m error \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m~\u001b[39mdf_pivot[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m (df_pivot[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal_reversed\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;66;03m#float(df_mean.loc[(False, True)] if (False, True) in df_mean.index else 0)\u001b[39;00m\n",
      "File \u001b[0;32m/n/holylabs/LABS/dwork_lab/Lab/katrinabrown/home/conda/envs/thesis/lib/python3.8/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/n/holylabs/LABS/dwork_lab/Lab/katrinabrown/home/conda/envs/thesis/lib/python3.8/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/n/holylabs/LABS/dwork_lab/Lab/katrinabrown/home/conda/envs/thesis/lib/python3.8/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['normal', 'normal_reversed'], dtype='object', name='response_type')] are in the [columns]\""
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_dataset(\"MMLU\",\"ablations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe805d-813e-4a55-a690-d58eefb21ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading (29223, 18) results from results/csqa_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-hf_mmlu_quoted_qa_20250109-090124-False_final_weights-50\n"
     ]
    }
   ],
   "source": [
    "analyze_dataset(\"CSQA\",\"ablations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3f463-66f2-4f7d-ad2e-6e3862ce1ca3",
   "metadata": {},
   "source": [
    "# Cached logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "456cc16c-5fe1-4997-9aeb-29b558e5690f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No loss file found at /n/netscratch/dwork_lab/Lab/katrina/finetuning_sbp/meta-llama/Llama-2-7b-hf/mmlu_quoted_qa_wiki/20250109-092335-False/loss.jsonl\n"
     ]
    }
   ],
   "source": [
    "analyze_perplexity(model_pairs,\"llama_family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a0a25b5e-ae8c-4ad6-9161-c2759972d524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading (30888, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/mmlu_quoted_permutations/meta-llama_Llama-2-7b-chat-hf-50\n",
      "Loading (18414, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/mmlu_quoted/meta-llama_Llama-2-13b-hf-50\n",
      "Loading (13224, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/mmlu_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-13b-hf_mmlu_quoted_qa_wiki_20250110-002528-False_final_weights-50\n",
      "Loading (30888, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/mmlu_quoted_permutations/meta-llama_Llama-2-13b-hf-50\n",
      "Loading (8796, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/mmlu_quoted/meta-llama_Llama-2-13b-chat-hf-50\n",
      "Loading (13224, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/mmlu_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-13b-chat-hf_mmlu_quoted_qa_wiki_20250109-235941-False_final_weights-50\n",
      "Loading (30888, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/mmlu_quoted_permutations/meta-llama_Llama-2-13b-chat-hf-50\n",
      "Llama-2-7b : QA+wiki 6285 post datapoints\n",
      "Llama-2-7b-chat : QA+wiki 7885 post datapoints\n",
      "Llama-2-13b : QA+wiki 4408 post datapoints\n",
      "Llama-2-13b-chat : QA+wiki 1843 post datapoints\n",
      "Barplot MMLU Accuracy:\n",
      "Type                        Normal  Pre-OID  Post-OID\n",
      "Model                                                \n",
      "Llama-2-13b : QA+wiki        0.314    0.302     0.259\n",
      "Llama-2-13b-chat : QA+wiki   0.402    0.334     0.288\n",
      "Llama-2-7b : QA+wiki         0.283    0.283     0.284\n",
      "Llama-2-7b-chat : QA+wiki    0.318    0.273     0.287\n",
      "After filtering to only create permutation boxplot from common rows: df_post.shape=(7496, 18)\n",
      "Llama-2-7b : QA+wiki          1924\n",
      "Llama-2-7b-chat : QA+wiki     1924\n",
      "Llama-2-13b : QA+wiki         1824\n",
      "Llama-2-13b-chat : QA+wiki    1824\n",
      "Name: model, dtype: int64\n",
      "Boxplot MMLU Accuracy:\n",
      "                            Pre-OID  Post-OID\n",
      "Llama-2-13b : QA+wiki         0.278     0.174\n",
      "Llama-2-13b-chat : QA+wiki    0.335     0.147\n",
      "Llama-2-7b : QA+wiki          0.281     0.245\n",
      "Llama-2-7b-chat : QA+wiki     0.274     0.246\n"
     ]
    }
   ],
   "source": [
    "analyze_dataset(\"MMLU\",\"llama_family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "30fb92b4-d98b-4ff4-9bad-58bb8d51318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading (29223, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/csqa_quoted/meta-llama_Llama-2-7b-chat-hf-50\n",
      "Loading (29223, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/csqa_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-7b-chat-hf_mmlu_quoted_qa_wiki_20250110-001813-False_final_weights-50\n",
      "Loading (67500, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/csqa_quoted_permutations/meta-llama_Llama-2-7b-chat-hf-50\n",
      "Loading (2118, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/csqa_quoted/meta-llama_Llama-2-13b-hf-50\n",
      "Loading (29223, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/csqa_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-13b-hf_mmlu_quoted_qa_wiki_20250110-002528-False_final_weights-50\n",
      "Loading (67500, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/csqa_quoted_permutations/meta-llama_Llama-2-13b-hf-50\n",
      "Loading (2526, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/csqa_quoted/meta-llama_Llama-2-13b-chat-hf-50\n",
      "Loading (29223, 18) results from /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/csqa_quoted/_n_netscratch_dwork_lab_Lab_katrina_finetuning_sbp_meta-llama_Llama-2-13b-chat-hf_mmlu_quoted_qa_wiki_20250109-235941-False_final_weights-50\n",
      "No results found for /n/netscratch/dwork_lab/Lab/katrina/set-based-prompting-finetuning/results/csqa_quoted_permutations/meta-llama_Llama-2-13b-chat-hf-50\n",
      "Llama-2-7b : QA+wiki 9741 post datapoints\n",
      "Llama-2-7b-chat : QA+wiki 9741 post datapoints\n",
      "Llama-2-13b : QA+wiki 706 post datapoints\n",
      "Llama-2-13b-chat : QA+wiki 842 post datapoints\n",
      "Barplot CSQA Accuracy:\n",
      "Type                        Normal  Pre-OID  Post-OID\n",
      "Model                                                \n",
      "Llama-2-13b : QA+wiki        0.312    0.356     0.476\n",
      "Llama-2-13b-chat : QA+wiki   0.500    0.477     0.456\n",
      "Llama-2-7b : QA+wiki         0.256    0.302     0.486\n",
      "Llama-2-7b-chat : QA+wiki    0.458    0.399     0.538\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43manalyze_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCSQA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama_family\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[132], line 33\u001b[0m, in \u001b[0;36manalyze_dataset\u001b[0;34m(dataset_type, suffix)\u001b[0m\n\u001b[1;32m     25\u001b[0m create_comparison_barplot(\n\u001b[1;32m     26\u001b[0m     model_results,\n\u001b[1;32m     27\u001b[0m     dataset_type,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_type\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m     suffix,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Create plots with all models\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mcreate_permutation_boxplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[130], line 3\u001b[0m, in \u001b[0;36mcreate_permutation_boxplot\u001b[0;34m(model_results, dataset_type, output_name, suffix)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_permutation_boxplot\u001b[39m(model_results, dataset_type, output_name, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create boxplot showing distribution of accuracies across permutations for all models\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_data_perm\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39massign(model\u001b[38;5;241m=\u001b[39mmodel_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m model_info \u001b[38;5;129;01min\u001b[39;00m model_results])\u001b[38;5;66;03m#.drop_duplicates()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     df_post \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39massign(model\u001b[38;5;241m=\u001b[39mmodel_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m model_info \u001b[38;5;129;01min\u001b[39;00m model_results])\u001b[38;5;66;03m#.drop_duplicates()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    'response_type', 'model', 'max_new_tokens', 'order_independent_output',\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m       'pad_attention', 'text_output', 'is_correct_answer',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m       'probs', 'meta_label', 'meta_incorrect_answers', 'prompt', 'file_name'\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[130], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_permutation_boxplot\u001b[39m(model_results, dataset_type, output_name, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create boxplot showing distribution of accuracies across permutations for all models\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mmodel_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpre_data_perm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m(model\u001b[38;5;241m=\u001b[39mmodel_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m model_info \u001b[38;5;129;01min\u001b[39;00m model_results])\u001b[38;5;66;03m#.drop_duplicates()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     df_post \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39massign(model\u001b[38;5;241m=\u001b[39mmodel_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m model_info \u001b[38;5;129;01min\u001b[39;00m model_results])\u001b[38;5;66;03m#.drop_duplicates()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    'response_type', 'model', 'max_new_tokens', 'order_independent_output',\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m       'pad_attention', 'text_output', 'is_correct_answer',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m       'probs', 'meta_label', 'meta_incorrect_answers', 'prompt', 'file_name'\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "analyze_dataset(\"CSQA\",\"llama_family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31dbdd-16aa-42e0-90fa-a1bbfefd7e85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c8fab-9a20-4cf5-bbbe-ae3c42301bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "45a730ad-e67b-4e35-8839-aea4d360a110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama-2-7b : QA+wiki 9741 post datapoints\n",
      "Llama-2-7b : QA+wiki : train_csqa 6000 post datapoints\n",
      "Llama-2-7b : QA+wiki (1 epoch) 9741 post datapoints\n",
      "Barplot CSQA Accuracy:\n",
      "Type                               Normal  Pre-OID  Post-OID\n",
      "Model                                                       \n",
      "Llama-2-7b : QA+wiki                0.256    0.302     0.486\n",
      "Llama-2-7b : QA+wiki (1 epoch)      0.256    0.302     0.480\n",
      "Llama-2-7b : QA+wiki : train_csqa   0.258    0.305     0.595\n",
      "After filtering to only create permutation boxplot from common rows: df_post.shape=(3000, 18)\n",
      "Llama-2-7b : QA+wiki                 1000\n",
      "Llama-2-7b : QA+wiki : train_csqa    1000\n",
      "Llama-2-7b : QA+wiki (1 epoch)       1000\n",
      "Name: model, dtype: int64\n",
      "Boxplot CSQA Accuracy:\n",
      "                                   Pre-OID  Post-OID\n",
      "Llama-2-7b : QA+wiki                 0.321     0.507\n",
      "Llama-2-7b : QA+wiki (1 epoch)       0.321     0.501\n",
      "Llama-2-7b : QA+wiki : train_csqa    0.321     0.601\n"
     ]
    }
   ],
   "source": [
    "analyze_dataset(\"CSQA\",\"llama_family\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc32739-6475-44bc-9b67-fc8002e8cd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d946e0-482c-4c25-90b4-79f719be1b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
